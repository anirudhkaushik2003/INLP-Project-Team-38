05/08/2024 08:12:29 PM [INFO] featurizing the gcdc corpus: all for task: 3-way-classification with model architecture: vanilla
05/08/2024 08:12:31 PM [DEBUG] <<LOADING>> GCDC dataset from directory: /home2/anirudhkaushik/INLP-Project-Team-40/processed_data/GCDC
05/08/2024 08:12:31 PM [DEBUG] working on train dataset 
05/08/2024 08:12:31 PM [DEBUG] <Done>
05/08/2024 08:12:31 PM [DEBUG] working on dev dataset 
05/08/2024 08:12:32 PM [DEBUG] <Done>
05/08/2024 08:12:32 PM [DEBUG] ------------------------------------------------------------
05/08/2024 08:12:32 PM [INFO] post-processing the dataset
05/08/2024 08:12:32 PM [INFO] data preprocessed: 3200, sentences preprocessed: 3200
05/08/2024 08:12:32 PM [INFO] featurizing the datasets..
05/08/2024 08:12:32 PM [DEBUG] 3200 data instance processed. max sent_seq_length: 512
05/08/2024 08:12:35 PM [INFO] post-processing the dataset
05/08/2024 08:12:35 PM [INFO] data preprocessed: 800, sentences preprocessed: 800
05/08/2024 08:12:35 PM [INFO] featurizing the datasets..
05/08/2024 08:12:35 PM [DEBUG] 800 data instance processed. max sent_seq_length: 512
05/08/2024 08:12:35 PM [DEBUG] ------------------------------------------------------------
05/08/2024 08:12:35 PM [INFO] label distribution in train dataset (total count: 3200)
05/08/2024 08:12:35 PM [INFO] {2: 1520, 0: 1047, 1: 633}
05/08/2024 08:12:35 PM [INFO] label distribution in dev dataset (total count: 800)
05/08/2024 08:12:35 PM [INFO] {2: 379, 0: 262, 1: 159}
05/08/2024 08:12:35 PM [DEBUG] ------------------------------------------------------------
05/08/2024 08:12:36 PM [INFO] 
command line argument captured ..
05/08/2024 08:12:36 PM [INFO] ------------------------------------------------------------
05/08/2024 08:12:36 PM [INFO] processed_dataset_path - /home2/anirudhkaushik/INLP-Project-Team-40/processed_data
05/08/2024 08:12:36 PM [INFO] checkpoint_path - /ssd_scratch/cvit/anirudhkaushik/inlp_project_models/
05/08/2024 08:12:36 PM [INFO] gpus - 4
05/08/2024 08:12:36 PM [INFO] epochs - 10
05/08/2024 08:12:36 PM [INFO] batch_size - 2
05/08/2024 08:12:36 PM [INFO] learning_rate - 1e-06
05/08/2024 08:12:36 PM [INFO] clip_grad_norm - 0.0
05/08/2024 08:12:36 PM [INFO] weight_decay - 0.01
05/08/2024 08:12:36 PM [INFO] dropout_rate - 0.1
05/08/2024 08:12:36 PM [INFO] enable_scheduler - False
05/08/2024 08:12:36 PM [INFO] warmup_steps - 0.01
05/08/2024 08:12:36 PM [INFO] margin - 1.0
05/08/2024 08:12:36 PM [INFO] corpus - gcdc
05/08/2024 08:12:36 PM [INFO] sub_corpus - all
05/08/2024 08:12:36 PM [INFO] max_seq_len - 512
05/08/2024 08:12:36 PM [INFO] max_fact_count - 50
05/08/2024 08:12:36 PM [INFO] max_fact_seq_len - 50
05/08/2024 08:12:36 PM [INFO] permutation_count - 20
05/08/2024 08:12:36 PM [INFO] with_replacement - 1
05/08/2024 08:12:36 PM [INFO] train_dataset_count - 3200
05/08/2024 08:12:36 PM [INFO] val_dataset_count - 800
05/08/2024 08:12:36 PM [INFO] test_dataset_count - None
05/08/2024 08:12:36 PM [INFO] inverse_pra - 0
05/08/2024 08:12:36 PM [INFO] task - 3-way-classification
05/08/2024 08:12:36 PM [INFO] enable_kldiv - False
05/08/2024 08:12:36 PM [INFO] label_smoothing - 0.1
05/08/2024 08:12:36 PM [INFO] inference - False
05/08/2024 08:12:36 PM [INFO] online_mode - 1
05/08/2024 08:12:36 PM [INFO] logger_exp_name - gcdc-All-vanilla-3-way-classification-roberta-base
05/08/2024 08:12:36 PM [INFO] arch - vanilla
05/08/2024 08:12:36 PM [INFO] disable_mtl - 0
05/08/2024 08:12:36 PM [INFO] mtl_base_arch - vanilla
05/08/2024 08:12:36 PM [INFO] model_name - roberta-base
05/08/2024 08:12:36 PM [INFO] tf2_model_name - roberta-base
05/08/2024 08:12:36 PM [INFO] use_pretrained_tf2 - 0
05/08/2024 08:12:36 PM [INFO] sentence_pooling - none
05/08/2024 08:12:36 PM [INFO] freeze_emb_layer - False
05/08/2024 08:12:36 PM [INFO] exp_count - 0
05/08/2024 08:12:36 PM [INFO] fp16 - 0
05/08/2024 08:12:36 PM [INFO] ------------------------------------------------------------
05/08/2024 08:12:36 PM [DEBUG] initiating training process...
05/08/2024 08:12:43 PM [DEBUG] ModelWrapper(
  (doc_encoder): TransformerModel(
    (tf2): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(50265, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (task_head): TexClassificationHead(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (out_proj): Linear(in_features=768, out_features=3, bias=True)
  )
  (train_metric): Accuracy()
  (val_metric): Accuracy()
  (test_metric): Accuracy()
)
05/08/2024 08:12:43 PM [INFO] Model has 124647939 trainable parameters
05/08/2024 08:12:57 PM [DEBUG] about to start training loop...
05/08/2024 08:13:18 PM [INFO] epoch : 0 - average_val_loss : 1.144051, overall_val_acc : 0.000000
05/08/2024 08:14:26 PM [INFO] epoch : 0 - average_val_loss : 1.019617, overall_val_acc : 0.473750
05/08/2024 08:14:28 PM [INFO] epoch : 0 - average_train_loss : 1.072004, overall_train_acc : 0.436563
05/08/2024 08:15:36 PM [INFO] epoch : 1 - average_val_loss : 0.963041, overall_val_acc : 0.576250
05/08/2024 08:15:38 PM [INFO] epoch : 1 - average_train_loss : 1.004383, overall_train_acc : 0.526563
05/08/2024 08:16:46 PM [INFO] epoch : 2 - average_val_loss : 0.926710, overall_val_acc : 0.612500
05/08/2024 08:16:49 PM [INFO] epoch : 2 - average_train_loss : 0.883635, overall_train_acc : 0.613750
05/08/2024 08:17:56 PM [INFO] epoch : 3 - average_val_loss : 0.987326, overall_val_acc : 0.608750
05/08/2024 08:17:56 PM [INFO] epoch : 3 - average_train_loss : 0.833158, overall_train_acc : 0.640625
05/08/2024 08:19:03 PM [INFO] epoch : 4 - average_val_loss : 1.026062, overall_val_acc : 0.612500
05/08/2024 08:19:03 PM [INFO] epoch : 4 - average_train_loss : 0.820670, overall_train_acc : 0.651250
05/08/2024 08:20:10 PM [INFO] epoch : 5 - average_val_loss : 1.042094, overall_val_acc : 0.613750
05/08/2024 08:20:13 PM [INFO] epoch : 5 - average_train_loss : 0.814383, overall_train_acc : 0.664688
05/08/2024 08:21:21 PM [INFO] epoch : 6 - average_val_loss : 1.088810, overall_val_acc : 0.615000
05/08/2024 08:21:23 PM [INFO] epoch : 6 - average_train_loss : 0.735479, overall_train_acc : 0.678437
05/08/2024 08:22:31 PM [INFO] epoch : 7 - average_val_loss : 1.137275, overall_val_acc : 0.602500
05/08/2024 08:22:31 PM [INFO] epoch : 7 - average_train_loss : 0.733633, overall_train_acc : 0.691562
05/08/2024 08:22:39 PM [DEBUG] training done.
